We now extend the results presented in Chapter~\ref{ch:vcmine} and introduce
PARMA, a randomized parallel algorithm for approximate frequent itemset mining,
that makes the problem of Frequent Itemsets and Association Rules mining (FIM)
embarassingly parallel, thus exhibiting near-linear speedup with the number of
machines. PARMA combines random sampling and parallelization techniques in a
novel fashion.  It mines, in parallel, a set of small random samples and then
filters and aggregates the collections of frequent itemsets or association rules
obtained from each sample.  Our work is orthogonal to other approaches, like
PFP~\citep{LiWZZC08}, which focuses on parallelizing the mining phase in order
to decrease the corresponding component of the cost. Due to the use of random
sampling, the output of PARMA is an approximation of
the collection of FIs or ARs in the dataset, but leveraging on the results
presented in
Chapter~\ref{ch:vcmine}, PARMA offers tight probabilistic guarantees on the
quality of the approximated collections returned in output. In particular it
guarantees that the output is an $\varepsilon$-approximation of the real
collection with probability at least $1-\delta$, where $\varepsilon$ and
$\delta$ are parameters specified by the user (see Section~\ref{sec:parmadef} for
formal definitions). 
PARMA is designed on
MapReduce~\citep{DeanG08}, a novel parallel/distributed architecture that has
raised significant interest in the research and industry communities. MapReduce
is capable of handling very large datasets and efficiently executing parallel
algorithms like PARMA.

To our knowledge PARMA is the first algorithm to exploit the combination of
random sampling and parallelization for the task of Association Rules Mining. 

A number of previous works explored either parallel
algorithms~\citep{BuehrerPTKS07,CongHHP05,EHZaiane06,FangEtAl08,LiuLZT07,OzkuralUA11,JinYA05,Zaki99}
or random
sampling (see Sect.~\ref{sec:vcmineprevwork})
for the FIM task, but the two approaches have been seen somewhat orthogonal
until today. In PARMA, the disadvantages of either approach are evened out by
the advantages of the other. In the spirit of \emph{moving computation to the
data} to minimize communication, we avoid data replication, and preserve the
advantages of parallelization by using of multiple independent small random
samples of the dataset which are mined in parallel and have only their results
aggregated. Similarly, we are not subject to the inherent trade-off between the
size of the random sample and the accuracy of the approximation that can be
obtained from it, as PARMA would only have to mine more samples of the same size
in parallel to get higher quality approximations.

Although PARMA is not the first algorithm to use MapReduce to solve the
FIM task, it differs from and enhances previous
works~\citep{CryansRC10,GhotingKPK11,Hammoud11,LiWZZC08,LiZ11,YangLF10,ZhouZCLF10}
in two crucial aspects. First, it significantly reduces the data that is
replicated and transmitted in the \emph{shuffle} phase of MapReduce.  Second,
PARMA is not limited to the extraction of Frequent Itemsets but can also
directly compute the collection of Association Rules in MapReduce. In previous
works, association rules had to be created sequentially after the Frequent
Itemsets had been computed in MapReduce. 

We conducted an extensive experimental evaluation to test the relative
performance, scalability and accuracy of PARMA across a wide range of
parameters and datasets. Our results suggest that PARMA can
significantly outperform exact mining solutions, has
near-linear speedup, and, as data and nodes are scaled together, is
able to achieve near constant runtimes. Also, our accuracy evaluation
shows that PARMA consistently computes approximated collections
of higher quality than what can be analytically guaranteed.

In this chapter:
\begin{enumerate}
\item We present PARMA, the first randomized MapReduce algorithm for discovering
  approximate collections of frequent itemsets or association rules with
  near-linear speedup.
\item We provide analytical guarantees for the quality of the approximate
  results generated by the algorithm.
\item We demonstrate the effectiveness of PARMA on many datasets and compare
  the performance of our implementation to that of several exact FIM algorithms
  on MapReduce.
\end{enumerate}

