\section{Preliminaries}
\label{sec:parmadef}
In this chapter we show how to extract $\varepsilon$-approximations of the
collection of (top-$k$) Frequent Itemsets and Association Rules using MapReduce. See
Sect.~\ref{sec:vcminepreldm} for definitions about FIs, ARs, and approximations.
We focus here on introducing MapReduce.

MapReduce is a programming paradigm and an associated parallel
and distributed implementation for developing and executing parallel algorithms
to process massive datasets on clusters of commodity machines~\citep{DeanG08}.
Algorithms are specified in MapReduce using two functions, $\mathbf{map}$ and
$\mathbf{reduce}$. The input is seen as a sequence of ordered key-value pairs
$(k,v)$. The $\mathbf{map}$ function takes as input one such $(key,value)$ pair
at a time, and can produce a finite multiset of pairs
$\{(k_1,v_1),(k_2,v_2),\cdots\}$. Let $\mathcal{U}$ be the multiset
union of all the multisets produced by the $\mathbf{map}$ function when applied
to all input pairs. We can partition $\mathcal{U}$ into sets
$\mathcal{U}_{\bar{k}}$ indexed by a particular key $\bar{k}$.
$\mathcal{U}_{\bar{k}}$ contains all and only the values $v$ for which there are pairs
$(\bar{k},v)$ with key $\bar{k}$ produced by the function $\mathbf{map}$
($\mathcal{U}_{\bar{k}}$ is a multiset, so a particular value $v$ can appear
multiple times in $\mathcal{U}_{\bar{k}}$). The $\mathbf{reduce}$ function takes as
input a key $\bar{k}$ and the multiset $\mathcal{U}_{\bar{k}}$ and produce another set
$\{(k_1,v_1),(k_2,v_2),\cdots\}$. 
The output of $\mathbf{reduce}$ can be used as
input for another (different) $\mathbf{map}$ function to develop MapReduce
algorithms that complete in multiple \emph{rounds}. 
By definition, the $\mathbf{map}$ function can be executed in parallel for each
input pair. In the same way, the computation of the output of $\mathbf{reduce}$
for a specific key $k^*$ is independent from the computation for any other key $k'\neq
k^*$, so multiple copies of the $\mathbf{reduce}$ function can be executed
in parallel, one for each key $k$. We denote the machines executing the
$\mathbf{map}$ function as \emph{mappers} and those executing the
$\mathbf{reduce}$ function as $\emph{reducers}$. The latter will be indexed by
the key $k$ assigned to them, i.e., reducer $r$ processes the multiset
$\mathcal{U}_r$. The data produced by the mappers are split by key and
sent to the reducers in the so-called \emph{shuffle} step. Some implementations, 
including Hadoop and the one described by Google~\citep{DeanG08}, use sorting in
the shuffle step to perform the grouping of map outputs by key.
The shuffle is transparent
to the algorithm designer but, since it involves the transmission of (possibly very
large amount of) data across the network, can be very expensive.

